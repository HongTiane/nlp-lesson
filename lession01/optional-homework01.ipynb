{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def is_variable(pat):\n",
    "    return re.match(r'^\\?[A-Za-z]+$', pat)\n",
    "\n",
    "\n",
    "def pat_match(pattern, saying):\n",
    "    if not pattern or not saying: return []\n",
    "    \n",
    "    if is_variable(pattern[0]):\n",
    "        return [(pattern[0], saying[0])] + pat_match(pattern[1:], saying[1:])\n",
    "    else:\n",
    "        if pattern[0] != saying[0]: return []\n",
    "        else:\n",
    "            return pat_match(pattern[1:], saying[1:])\n",
    "        \n",
    "\n",
    "def pat_to_dict(patterns):\n",
    "    return {k: v for k, v in patterns}\n",
    "\n",
    "def subsitite(rule, parsed_rules):\n",
    "    if not rule: return []\n",
    "    \n",
    "    return [parsed_rules.get(rule[0], rule[0])] + subsitite(rule[1:], parsed_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_patterns = {\n",
    "    \"I need ?X\": [\"Image you will get ?X soon\", \"Why do you need ?X ?\"], \n",
    "    \"My ?X told me something\": [\"Talk about more about your ?X\", \"How do you think about your ?X ?\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_response(saying, rules=defined_patterns):\n",
    "    for pattern in rules.keys():\n",
    "        patterns = pat_match(pattern.split(), saying.split())\n",
    "        if patterns:\n",
    "            return ' '.join(subsitite(random.choice(rules[pattern]).split(), pat_to_dict(patterns)))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Image you will get iPhone soon'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('I need iPhone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do you think about your mother ?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('My mother told me something')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segment Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_pattern_segment(pattern):\n",
    "    return re.match(r'^\\?\\*[A-Za-z]+$', pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 10), match='?*pppppppp'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_pattern_segment('?*pppppppp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def pat_match_with_seg(pattern, saying):\n",
    "    if not pattern or not saying: return []\n",
    "    \n",
    "    pat = pattern[0]\n",
    "    \n",
    "    if is_variable(pat):\n",
    "        return [(pat, saying[0])] + pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    elif is_pattern_segment(pat):\n",
    "        match, index = segment_match(pattern, saying)\n",
    "        if not match: return []\n",
    "        return [match] + pat_match_with_seg(pattern[1:], saying[index:])\n",
    "    elif pat == saying[0]:\n",
    "        return pat_match_with_seg(pattern[1:], saying[1:])\n",
    "    else:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_match(pattern, saying):\n",
    "    seg_pat, rest = pattern[0], pattern[1:]\n",
    "    seg_pat = seg_pat.replace('?*', '?')\n",
    "\n",
    "    if not rest: return (seg_pat, saying), len(saying)    \n",
    "    \n",
    "    for i, token in enumerate(saying):\n",
    "        if rest[0] == token and is_match(rest[1:], saying[(i + 1):]):\n",
    "            return (seg_pat, saying[:i]), i\n",
    "    return (), -1\n",
    "\n",
    "def is_match(rest, saying):\n",
    "    if not rest and not saying:\n",
    "        return True\n",
    "    if not all(a.isalpha() for a in rest[0]):\n",
    "        return True\n",
    "    if rest[0] != saying[0]:\n",
    "        return False\n",
    "    return is_match(rest[1:], saying[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('?P', ['My', 'dog', 'and', 'my', 'cat']), 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_match('?*P is very good'.split(), \"My dog and my cat is very good\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('?P', ['My', 'dog']), ('?X', ['my', 'cat', 'is', 'very', 'cute'])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat_match_with_seg('?*P is very good and ?*X'.split(), \"My dog is very good and my cat is very cute\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pat_to_dict(patterns):\n",
    "    return {k: ' '.join(v) if isinstance(v, list) else v for k, v in patterns}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Why', 'do', 'you', 'neeed', 'an iPhone']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsitite(\"Why do you neeed ?X\".split(), pat_to_dict(pat_match_with_seg('I need ?*X'.split(), \n",
    "                  \"I need an iPhone\".split())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_patterns = {\n",
    "    \"?*X hello ?*Y\": [\"Hi, how do you do?\"],\n",
    "    \"I was ?*X\": [\"Were you really ?X ?\", \"I already knew you were ?X .\"]\n",
    "}\n",
    "def get_response(saying, rules=defined_patterns):\n",
    "    for pattern in rules.keys():\n",
    "        patterns = pat_match_with_seg(pattern.split(), saying.split())\n",
    "        if patterns:\n",
    "            return ' '.join(subsitite(random.choice(rules[pattern]).split(), pat_to_dict(patterns)))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I already knew you were a ipone .'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('I was a ipone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "def cut(sentence):\n",
    "    return list(jieba.cut(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pattern_split(pattern):\n",
    "    if is_chinese(pattern):\n",
    "        return chinese_split(pattern)\n",
    "    else:\n",
    "        return pattern.split(' ')\n",
    "    \n",
    "def sentence_split(sentence):\n",
    "    if is_chinese(sentence):\n",
    "        return cut(sentence)\n",
    "    else:\n",
    "        return sentence.split(' ')\n",
    "\n",
    "def is_chinese(sentence):\n",
    "    for c in sentence:\n",
    "        if '\\u4e00' <= c <= '\\u9fa5':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def chinese_split(pattern):\n",
    "    chinese_words = []\n",
    "    placeholders = re.findall(r'\\?[\\*]?[A-Za-z]+', pattern)\n",
    "    if placeholders:\n",
    "        pattern_index = 0\n",
    "        for placeholder in placeholders:\n",
    "            p_list = pattern[pattern_index:].split(placeholder)\n",
    "            chinese_words += cut(p_list[0])\n",
    "            chinese_words.append(placeholder)\n",
    "            pattern_index += len(p_list[0]) + len(placeholder)\n",
    "        chinese_words += cut(pattern[pattern_index:])\n",
    "    else:\n",
    "        chinese_words.append(cut(pattern))\n",
    "    return chinese_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ZENGYU~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.280 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['?*x', '你好', '?*y']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_split('?*x你好?*y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['我', '讨厌', '你']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_split('我讨厌你')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "defined_patterns = {\n",
    "    \"?*X hello ?*Y\": [\"Hi, how do you do?\"],\n",
    "    \"I was ?*X\": [\"Were you really ?X ?\", \"I already knew you were ?X .\"],\n",
    "    '?*x讨厌?*y': ['?y怎么会那么讨厌呢?', '?x讨厌?y的哪里？', '?y有什么不好呢？', '你不想要?y吗？']\n",
    "}\n",
    "def get_response(saying, rules=defined_patterns):\n",
    "    for pattern in rules.keys():\n",
    "        patterns = pat_match_with_seg(pattern_split(pattern), sentence_split(saying))\n",
    "        if patterns:\n",
    "            return ' '.join(subsitite(pattern_split(random.choice(rules[pattern])), pat_to_dict(patterns)))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I already knew you were a ipone .'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('I was a ipone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'你 不 想要 一群 小狗 吗 ？'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_response('小红、小明和小东讨厌一群小狗')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 问题4"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1、这样的程序有什么优点？有什么缺点？你有什么可以改进的方法吗？\n",
    "优点是可以随时调整和扩展pattern来实现更丰富的交流\n",
    "缺点是不能动态的调整占位符，调整占位符需要修改代码\n",
    "改进方法将占位符作为参数从外部传进函数\n",
    "\n",
    "2、什么是数据驱动？数据驱动在这个程序里如何体现？\n",
    "数据驱动：通过数据分析和价值发现改善客户、产品、基础设施、盈利方式等核心环节,形成独特的竞争优势,最终实现整个企业乃至供应链的快速运转\n",
    "在本程序中通过pattern实现了根据用户输入的句子进行给出相应的回应体现了通过已有的数据模型pattern实现一种简单的相互交流的功能\n",
    "3、数据驱动与 AI 的关系是什么？\n",
    "AI是基于数据驱动的，AI需要通过大量的数据进行计算分析训练模型，通过这些模型来推断用户的行为。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
